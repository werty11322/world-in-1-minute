import feedparser
import requests
from datetime import datetime
import os

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
RSS_FEEDS = [
    'http://feeds.bbci.co.uk/news/rss.xml',
    'http://feeds.reuters.com/reuters/topNews'
]

def fetch_news(feeds):
    """–ü–∞—Ä—Å–∏–º RSS-–ª–µ–Ω—Ç—ã –∏ —Å–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏."""
    articles = []
    for feed_url in feeds:
        feed = feedparser.parse(feed_url)
        for entry in feed.entries[:5]:
            full_text = f"{entry.title}. {entry.get('summary', '')}"
            articles.append({
                'title': entry.title,
                'link': entry.link,
                'source': feed.feed.title,
                'full_text': full_text
            })
    return articles

def summarize_text(text):
    """–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é Hugging Face API."""
    HF_API_TOKEN = os.environ['HFTOKEN']
    api_url = "https://api-inference.huggingface.co/models/facebook/bart-large-cnn"
    headers = {"Authorization": f"Bearer {HF_API_TOKEN}"}
    payload = {"inputs": text}
    
    try:
        response = requests.post(api_url, headers=headers, json=payload)
        result = response.json()
        if isinstance(result, list) and len(result) > 0:
            return result[0]['summary_text']
        else:
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é."
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {e}"

def send_to_telegram(message):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –≤ Telegram-–∫–∞–Ω–∞–ª."""
    TELEGRAM_BOT_TOKEN = os.environ['TGBOT']
    TELEGRAM_CHAT_ID = os.environ['TGCHAT']
    
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": message,
        "parse_mode": "Markdown",
        "disable_web_page_preview": True
    }
    
    response = requests.post(url, json=payload)
    return response.json()

def main():
    print("–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π...")
    articles = fetch_news(RSS_FEEDS)
    print(f"–ü–æ–ª—É—á–µ–Ω–æ {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π. –ù–∞—á–∏–Ω–∞–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é...")
    
    digest = f"# üåç –ú–∏—Ä –∑–∞ –º–∏–Ω—É—Ç—É | {datetime.now().strftime('%d.%m.%Y')}\n\n"
    
    for i, article in enumerate(articles[:8], 1):
        digest += f"**{i}. {article['title']}**\n"
        digest += f"*–ò—Å—Ç–æ—á–Ω–∏–∫: {article['source']}*\n"
        
        summary = summarize_text(article['full_text'])
        digest += f"üìå {summary}\n"
        digest += f"üîó [–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é]({article['link']})\n\n"
    
    print("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Telegram...")
    result = send_to_telegram(digest)
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏:", result)
    
    with open("last_digest.md", "w", encoding="utf-8") as f:
        f.write(digest)

if __name__ == "__main__":
    main()
